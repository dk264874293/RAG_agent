'''
Author: 汪培良 rick_wang@yunquna.com
Date: 2026-01-07 08:12:42
LastEditors: 汪培良 rick_wang@yunquna.com
LastEditTime: 2026-01-07 18:55:56
FilePath: /RAG_agent/src/splitter/text_splitter.py
Description: 这是默认设置,请设置`customMade`, 打开koroFileHeader查看配置 进行设置: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
'''
import os
from dotenv import load_dotenv
from llama_index.core import VectorStoreIndex, Settings, Document
from llama_index.core.node_parser import SentenceWindowNodeParser, SemanticSplitterNodeParser, TokenTextSplitter
from llama_index.core.postprocessor import MetadataReplacementPostProcessor
from src.extractor.pdf_extractor import PdfExtractor

# 导入 OpenAILike LLM (用于 DashScope 兼容模式，Qwen 模型)
from llama_index.llms.openai_like import OpenAILike 
# 导入 DashScopeEmbedding (用于阿里云 DashScope 嵌入模型)
from llama_index.core import Document as LlamaDocument

from llama_index.embeddings.dashscope import DashScopeEmbedding 
load_dotenv()
DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')

Settings.llm = OpenAILike(
    model="qwen-plus",
    api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=DASHSCOPE_API_KEY,
    is_chat_model=True,
    temperature=0.1 # 添加温度参数，用于控制生成随机性
) 

# 2. 配置嵌入模型 (使用 DashScopeEmbedding 类)
Settings.embed_model = DashScopeEmbedding(
    model_name="text-embedding-v3", 
    api_key=DASHSCOPE_API_KEY,     
)

def evaluate_splitter(splitter,documents,question,splitter_name):
    """
    评测不同文档切片方法的效果
    手动打印召回结果，方便直接对比切分效果。
    """
    print(f"\n{'='*50}")
    print(f"正在使用 {splitter_name} 方法进行测试...")
    print(f"{'='*50}\n")

    # 显示 raw chunks generated by the splitter
    print(f"【{splitter_name}】生成的原始文档切片 (Nodes):")
    raw_nodes = splitter.get_nodes_from_documents(documents)
    for i, node in enumerate(raw_nodes, 1):
        print(f"\n 切片{i}")
        if isinstance(splitter, SentenceWindowNodeParser):
            original_text = node.metadata.get("original_text", node.get_content())
            window_context = node.metadata.get("window", "N/A - 窗口内容未生成")
            print(f"   核心内容: \"{original_text}\"")
            print(f"   完整窗口上下文(供LLM用): \"{window_context}\"")
        else:
            print(f" 内容： \"{node.get_content()}")
        print("   " + "-" * 40)
    print("\n" + "=" * 50)
    print(f"\n{splitter_name} 测试完成。")
    print(f"{'='*50}\n")

current_dir = os.path.dirname(os.path.abspath(__file__))
# 构建test.pdf的绝对路径
file_path = os.path.join(current_dir, "test.pdf")
extractor = PdfExtractor(file_path = file_path,tenant_id = "1",user_id = "1")
custom_documents = extractor.extract()
documents = []
for doc in custom_documents:
    # 转换为LlamaIndex的Document，使用page_content作为text字段
    llama_doc = LlamaDocument(
        text=doc.page_content,
        metadata=doc.metadata
    )
    documents.append(llama_doc)

question = "LlamaIndex 的主要功能和核心概念是什么？以及两种高级切片策略的区别？"

token_splitter = TokenTextSplitter(
    chunk_size = 500,
    chunk_overlap=100
)

evaluate_splitter(token_splitter,documents,question,"Token 切片 (chunk_size=30)")